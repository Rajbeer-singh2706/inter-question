{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "PySpark Basics & Advanced:\n",
    "\n",
    "What are RDDs in PySpark? How do they differ from DataFrames?\n",
    "Explain the concept of lazy evaluation in PySpark.\n",
    "How does PySpark handle data partitioning? How would you optimize it?\n",
    "Discuss the differences between map, flatMap, and reduce operations in PySpark.\n",
    "Data Processing & Transformation:\n",
    "\n",
    "Write a PySpark job to read data from a CSV file, transform it, and save the result as a Parquet file.\n",
    "How would you join large datasets in PySpark efficiently?\n",
    "Explain how you would handle skewed data in PySpark.\n",
    "Problem Solving:\n",
    "\n",
    "Write a PySpark job to calculate the moving average of a column in a large dataset.\n",
    "Implement a PySpark script to deduplicate records from a dataset.\n",
    "Write a PySpark job to identify the top 10 most frequent words in a large text dataset.\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
