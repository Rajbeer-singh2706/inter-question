Deloitte Pyspark interview questions for Data Engineer 2024.

1. Can you provide an overview of your experience working with PySpark and big data processing?
2. What motivated you to specialize in PySpark, and how have you applied it in your previous roles?
3. Explain the basic architecture of PySpark.
4. How does PySpark relate to Apache Spark, and what advantages does it offer in distributed data processing?
5. Describe the difference between a DataFrame and an RDD in PySpark.
6. Can you explain transformations and actions in PySpark DataFrames?
7. Provide examples of PySpark DataFrame operations you frequently use.
8. How do you optimize the performance of PySpark jobs?
9. Can you discuss techniques for handling skewed data in PySpark?
10. Explain how data serialization works in PySpark.
11. Discuss the significance of choosing the right compression codec for your PySpark applications.
12. How do you deal with missing or null values in PySpark DataFrames?
13. Are there any specific strategies or functions you prefer for handling missing data?
14. Describe your experience with PySpark SQL.
15. How do you execute SQL queries on PySpark DataFrames?
16. What is broadcasting, and how is it useful in PySpark?
17. Provide an example scenario where broadcasting can significantly improve performance.
18. Discuss your experience with PySparks MLlib.
19. Can you give examples of machine learning algorithms youve implemented using PySpark?
20. How do you monitor and troubleshoot PySpark jobs?


What is AQE 
What is dynamic Partition Pruning ?
